{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import gc\n",
    "import resource\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples, 32 channels, 32x3\n",
      "10000  test samples, 32 channels, 32x3\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_classes = 100\n",
    "nb_classes = 20\n",
    "epochs = 50\n",
    "learning_rate = 3e-4\n",
    "from keras.datasets import cifar100\n",
    "from keras.utils import np_utils\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data('coarse')\n",
    "(Xf_train, yf_train), (Xf_test, yf_test) = cifar100.load_data('fine')\n",
    "\n",
    "# print shape of data while model is building\n",
    "print(\"{1} train samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_train.shape[1] == 1 else \"s\", *X_train.shape))\n",
    "print(\"{1}  test samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_test.shape[1] == 1 else \"s\", *X_test.shape))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Yf_train = np_utils.to_categorical(yf_train, num_classes)\n",
    "Yf_test = np_utils.to_categorical(yf_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "torch.Size([50000])\n",
      "torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "tensor_x_train = torch.Tensor(X_train).permute(0,3,1,2)\n",
    "tensor_x_test = torch.Tensor(X_test).permute(0,3,1,2)\n",
    "tensor_yc_train = torch.LongTensor(y_train.flatten())\n",
    "tensor_yf_train = torch.LongTensor(yf_train.flatten())\n",
    "print(tensor_x_train.shape)\n",
    "print(tensor_x_test.shape)\n",
    "print(tensor_yc_train.shape)\n",
    "print(tensor_yf_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3, 32, 32])\n",
      "torch.Size([10000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "tensor_yc_test = torch.LongTensor(y_test.flatten())\n",
    "tensor_yf_test = torch.LongTensor(yf_test.flatten())\n",
    "print(tensor_x_test.shape)\n",
    "print(tensor_yc_test.shape)\n",
    "print(tensor_yf_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(tensor_x_train,tensor_yc_train,tensor_yf_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(tensor_x_test,tensor_yc_test,tensor_yf_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([200, 400])\n",
      "torch.Size([200])\n",
      "torch.Size([20, 200])\n",
      "torch.Size([20])\n",
      "torch.Size([100, 200])\n",
      "torch.Size([100])\n",
      "Parameter containing:\n",
      "tensor([ 0.0627,  0.0513, -0.0546, -0.0143, -0.0347,  0.0447, -0.0318, -0.0440,\n",
      "         0.0657, -0.0205, -0.0656, -0.0663,  0.0168,  0.0119,  0.0176, -0.0639,\n",
      "        -0.0173,  0.0437,  0.0141, -0.0325, -0.0501,  0.0411,  0.0396,  0.0260,\n",
      "         0.0545,  0.0684, -0.0576,  0.0523,  0.0330, -0.0278,  0.0587,  0.0655,\n",
      "        -0.0617, -0.0169, -0.0051, -0.0030, -0.0338,  0.0105,  0.0293,  0.0419,\n",
      "         0.0131,  0.0347,  0.0150, -0.0024, -0.0266, -0.0299, -0.0074,  0.0020,\n",
      "        -0.0391, -0.0534,  0.0592,  0.0258,  0.0576,  0.0151,  0.0322, -0.0010,\n",
      "         0.0578, -0.0596, -0.0053, -0.0321,  0.0667,  0.0125,  0.0038,  0.0229,\n",
      "         0.0295,  0.0132,  0.0030,  0.0648,  0.0619,  0.0183,  0.0196, -0.0560,\n",
      "        -0.0376, -0.0427, -0.0701, -0.0190, -0.0073,  0.0209,  0.0626,  0.0127,\n",
      "        -0.0481, -0.0242,  0.0468,  0.0387,  0.0563, -0.0200,  0.0214,  0.0511,\n",
      "         0.0487, -0.0666,  0.0653,  0.0390,  0.0313,  0.0407, -0.0432,  0.0697,\n",
      "         0.0424, -0.0117,  0.0629,  0.0342], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) #28*28*6\n",
    "        self.pool = nn.MaxPool2d(2, 2) #14*14*6\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) #5*5*16\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 200)\n",
    "        self.fc2 = nn.Linear(200, 20)\n",
    "        self.fc3 = nn.Linear(200, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x)) #16 * 5 * 5\n",
    "        x = F.relu(self.fc1(x))\n",
    "        y = self.fc2(x)\n",
    "        z = self.fc3(x)\n",
    "        return y,z\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "for i in net.parameters():\n",
    "    print(i.shape)\n",
    "    if i.shape == torch.Size([100]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayanth/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:31: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "Epoch [1/50], Iter [20/0] Loss: nan, nan, nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "Epoch [1/50], Iter [40/0] Loss: nan, nan, nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "Epoch [1/50], Iter [60/0] Loss: nan, nan, nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n",
      "Epoch [1/50], Iter [80/0] Loss: nan, nan, nan\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "alpha nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-bd0ad8e86631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mlossf_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mlossgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jayanth/Library/Python/2.7/lib/python/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jayanth/Library/Python/2.7/lib/python/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# Loss and Optimizer\n",
    "\n",
    "#Can also try nn.MSELoss()\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.03)\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "trainc_acc = []\n",
    "valc_acc = []\n",
    "trainf_acc = []\n",
    "valf_acc = []\n",
    "\n",
    "loss_history = []\n",
    "lossc_history = []\n",
    "lossf_history = []\n",
    "\n",
    "alpha = np.random.random_sample()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labelc, labelf) in enumerate(train_loader):\n",
    "        net.train() # Change model to 'train' mode.\n",
    "    #     for i in range(cnn_training_data_X.shape[0]):\n",
    "        images = Variable(images, requires_grad=True) #unsqueeze used to make a 4d tensor because \n",
    "    #     print images.shape\n",
    "        labelc = Variable(labelc, requires_grad=False)\n",
    "        labelf = Variable(labelf, volatile=True)\n",
    "        #labels = [labelc, labelf]\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        net.zero_grad()\n",
    "        #outputs = net(images)\n",
    "        \n",
    "        \n",
    "        outc, outf = net(images)\n",
    "        lossc = criterion1(outc, labelc)\n",
    "        lossf = criterion2(outf, labelf)\n",
    "        \n",
    "        loss = alpha*lossc + (1-alpha)*lossf\n",
    "        \n",
    "        #loss = criterion(outputs, labelc)\n",
    "        #loss.backward()\n",
    "        \n",
    "        loss_history.append(loss.data)\n",
    "        lossc_history.append(lossc.data)\n",
    "        lossf_history.append(lossf.data)\n",
    "        \n",
    "        loss.backward()\n",
    "        lossgrad = images.grad\n",
    "        \n",
    "        losscgrad = (1-alpha)*lossgrad/alpha\n",
    "        lossfgrad = alpha*lossgrad/(1-alpha)\n",
    "        \n",
    "        losscgradnorm = torch.norm(torch.norm(torch.norm(torch.norm(losscgrad, 2, 0),2,0),2,0),2,0)\n",
    "        lossfgradnorm = torch.norm(torch.norm(torch.norm(torch.norm(lossfgrad, 2, 0),2,0),2,0),2,0)\n",
    "        alpha = (lossfgradnorm**2)/((lossfgradnorm**2) + (losscgradnorm**2))\n",
    "        \n",
    "        print(losscgradnorm)\n",
    "        print(lossfgradnorm)\n",
    "        print(torch.norm(torch.norm(torch.norm(torch.norm(lossgrad, 2, 0),2,0),2,0),2,0))\n",
    "        print('alpha %.3f'%(alpha))\n",
    "        \n",
    "        for f in net.parameters():\n",
    "            if f.shape != torch.Size([100]) and f.shape != torch.Size([100, 200]):\n",
    "                f.data.sub_(alpha * f.grad.data * learning_rate)\n",
    "            \n",
    "        for f in net.parameters():\n",
    "            if f.shape != torch.Size([20]) and f.shape != torch.Size([20, 200]):\n",
    "                f.data.sub_(alpha * f.grad.data * learning_rate)\n",
    "\n",
    "        #optimizer.step()\n",
    "        if (i+1) % 20 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, %.4f, %.4f' \n",
    "                   %(epoch+1, epochs, i+1, len(X_train.shape)//batch_size, lossc.data, lossf.data,loss.data))\n",
    "    print('[%d/%d] Loss: %.3f' % (epoch+1, epochs, np.mean(loss_history)))\n",
    "    \n",
    "    \n",
    "    correctc = 0\n",
    "    correctf = 0\n",
    "    total = 0\n",
    "    net.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            images, labelc, labelf = data\n",
    "            outputc, outputf = net(images)\n",
    "            _, predictedc = torch.max(outputc.data, 1)\n",
    "            _, predictedf = torch.max(outputf.data, 1)\n",
    "            total += labelc.size(0)\n",
    "            correctc += (predictedc == labelc).sum().item()\n",
    "            correctf += (predictedf == labelf).sum().item()\n",
    "    print(total)\n",
    "    trainc_acc_val = (100 * correctc / total)\n",
    "    trainf_acc_val = (100 * correctf / total)\n",
    "    train_acc_val = (trainc_acc_val + trainf_acc_val)/2.0\n",
    "    trainc_acc.append(trainc_acc_val)\n",
    "    trainf_acc.append(trainf_acc_val)\n",
    "    train_acc.append(train_acc_val)\n",
    "    print('Accuracy of the network on the 50000 test images coarse: %d %%' % (trainc_acc_val))\n",
    "    print('Accuracy of the network on the 50000 test images fine: %d %%' % (trainf_acc_val))\n",
    "    print('Average Accuracy of the network on the 50000 test images: %d %%' % (train_acc_val))\n",
    "          \n",
    "    correctc = 0\n",
    "    correctf = 0\n",
    "    total = 0\n",
    "    net.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labelc, labelf = data\n",
    "            outputc, outputf = net(images)\n",
    "            _, predictedc = torch.max(outputc.data, 1)\n",
    "            _, predictedf = torch.max(outputf.data, 1)\n",
    "            total += labelc.size(0)\n",
    "            correctc += (predictedc == labelc).sum().item()\n",
    "            correctf += (predictedf == labelf).sum().item()\n",
    "\n",
    "    valc_acc_val = (100 * correctc / total)\n",
    "    valf_acc_val = (100 * correctf / total)\n",
    "    val_acc_val = (valc_acc_val + valf_acc_val)/2.0\n",
    "    valc_acc.append(valc_acc_val)\n",
    "    valf_acc.append(valf_acc_val)\n",
    "    val_acc.append(val_acc_val)\n",
    "    print('Accuracy of the network on the 50000 test images coarse: %d %%' % (valc_acc_val))\n",
    "    print('Accuracy of the network on the 50000 test images fine: %d %%' % (valf_acc_val))\n",
    "    print('Average Accuracy of the network on the 50000 test images: %d %%' % (val_acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot train/val accuracies\n",
    "print(train_acc)\n",
    "plt.title(\"Train/Test Acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel('acc')\n",
    "plt.plot(train_acc, color='red')\n",
    "plt.plot(val_acc, color='blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
