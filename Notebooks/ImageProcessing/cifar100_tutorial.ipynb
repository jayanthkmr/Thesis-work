{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import torch.utils.data\n",
    "import gc\n",
    "import resource\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples, 32 channels, 32x3\n",
      "10000  test samples, 32 channels, 32x3\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_classes = 100\n",
    "nb_classes = 20\n",
    "epochs = 50\n",
    "learning_rate = 3e-4\n",
    "from keras.datasets import cifar100\n",
    "from keras.utils import np_utils\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data('coarse')\n",
    "(Xf_train, yf_train), (Xf_test, yf_test) = cifar100.load_data('fine')\n",
    "\n",
    "# print shape of data while model is building\n",
    "print(\"{1} train samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_train.shape[1] == 1 else \"s\", *X_train.shape))\n",
    "print(\"{1}  test samples, {2} channel{0}, {3}x{4}\".format(\"\" if X_test.shape[1] == 1 else \"s\", *X_test.shape))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Yf_train = np_utils.to_categorical(yf_train, num_classes)\n",
    "Yf_test = np_utils.to_categorical(yf_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "torch.Size([50000])\n",
      "torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "tensor_x_train = torch.Tensor(X_train).permute(0,3,1,2)\n",
    "tensor_x_test = torch.Tensor(X_test).permute(0,3,1,2)\n",
    "tensor_yc_train = torch.LongTensor(y_train.flatten())\n",
    "tensor_yf_train = torch.LongTensor(yf_train.flatten())\n",
    "print(tensor_x_train.shape)\n",
    "print(tensor_x_test.shape)\n",
    "print(tensor_yc_train.shape)\n",
    "print(tensor_yf_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3, 32, 32])\n",
      "torch.Size([10000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "tensor_yc_test = torch.LongTensor(y_test.flatten())\n",
    "tensor_yf_test = torch.LongTensor(yf_test.flatten())\n",
    "print(tensor_x_test.shape)\n",
    "print(tensor_yc_test.shape)\n",
    "print(tensor_yf_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(tensor_x_train,tensor_yc_train,tensor_yf_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(tensor_x_test,tensor_yc_test,tensor_yf_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    \"\"\"Implements Adam algorithm.\n",
    "\n",
    "    It has been proposed in `Adam: A Method for Stochastic Optimization`_.\n",
    "\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): learning rate (default: 1e-3)\n",
    "        betas (Tuple[float, float], optional): coefficients used for computing\n",
    "            running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
    "            algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
    "\n",
    "    .. _Adam\\: A Method for Stochastic Optimization:\n",
    "        https://arxiv.org/abs/1412.6980\n",
    "    .. _On the Convergence of Adam and Beyond:\n",
    "        https://openreview.net/forum?id=ryQu7f-RZ\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
    "                 weight_decay=0, amsgrad=False):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "        super(Adam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Adam, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('amsgrad', False)\n",
    "    \n",
    "    def step(self, alpha, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                amsgrad = group['amsgrad']\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                    if amsgrad:\n",
    "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                if amsgrad:\n",
    "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    grad = grad.add(group['weight_decay'], p.data)\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                if amsgrad:\n",
    "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
    "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
    "                    # Use the max. for normalizing running avg. of gradient\n",
    "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                else:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                step_size = alpha * group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 32, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([512, 2304])\n",
      "torch.Size([512])\n",
      "torch.Size([20, 512])\n",
      "torch.Size([20])\n",
      "torch.Size([100, 512])\n",
      "torch.Size([100])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "            Conv2d-2           [-1, 32, 30, 30]           9,248\n",
      "         MaxPool2d-3           [-1, 32, 15, 15]               0\n",
      "         Dropout2d-4           [-1, 32, 15, 15]               0\n",
      "            Conv2d-5           [-1, 64, 15, 15]          18,496\n",
      "            Conv2d-6           [-1, 64, 13, 13]          36,928\n",
      "         MaxPool2d-7             [-1, 64, 6, 6]               0\n",
      "         Dropout2d-8             [-1, 64, 6, 6]               0\n",
      "            Linear-9                  [-1, 512]       1,180,160\n",
      "          Dropout-10                  [-1, 512]               0\n",
      "           Linear-11                   [-1, 20]          10,260\n",
      "          Softmax-12                   [-1, 20]               0\n",
      "           Linear-13                  [-1, 100]          51,300\n",
      "          Softmax-14                  [-1, 100]               0\n",
      "================================================================\n",
      "Total params: 1,307,288\n",
      "Trainable params: 1,307,288\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.82\n",
      "Params size (MB): 4.99\n",
      "Estimated Total Size (MB): 5.82\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayanth/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/jayanth/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) #32*32*32\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=0) #32*32*32\n",
    "        self.pool = nn.MaxPool2d(2, 2) #14*14*6\n",
    "        self.dropout = nn.Dropout2d(p=0.25)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1) #32*32*32\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=0) #32*32*32\n",
    "        self.fc1 = nn.Linear(2304, 512)\n",
    "        self.dropout1d = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(512, 20)\n",
    "        self.fc3 = nn.Linear(512, 100)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(self.pool(F.relu(self.conv2(x))))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(self.pool(F.relu(self.conv4(x))))\n",
    "        x = x.view(-1, self.num_flat_features(x)) #16 * 5 * 5\n",
    "        x = self.dropout1d(self.fc1(x))\n",
    "        y = self.softmax(self.fc2(x))\n",
    "        z = self.softmax(self.fc3(x))\n",
    "        return y,z\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "for i in net.parameters():\n",
    "    print(i.shape)\n",
    "    \n",
    "summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayanth/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:29: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/jayanth/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/jayanth/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6049)\n",
      "Epoch [1/50], Iter [20/0] Loss: 3.0049, 4.6012, 7.6061\n",
      "tensor(0.6068)\n",
      "Epoch [1/50], Iter [40/0] Loss: 2.9793, 4.5970, 7.5763\n",
      "tensor(0.6073)\n",
      "Epoch [1/50], Iter [60/0] Loss: 2.9718, 4.5967, 7.5685\n",
      "tensor(0.6091)\n",
      "Epoch [1/50], Iter [80/0] Loss: 2.9430, 4.5866, 7.5296\n",
      "tensor(0.6092)\n",
      "Epoch [1/50], Iter [100/0] Loss: 2.9432, 4.5882, 7.5314\n",
      "tensor(0.6107)\n",
      "Epoch [1/50], Iter [120/0] Loss: 2.9217, 4.5833, 7.5051\n",
      "tensor(0.6080)\n",
      "Epoch [1/50], Iter [140/0] Loss: 2.9582, 4.5884, 7.5466\n",
      "tensor(0.6098)\n",
      "Epoch [1/50], Iter [160/0] Loss: 2.9397, 4.5937, 7.5335\n",
      "tensor(0.6096)\n",
      "Epoch [1/50], Iter [180/0] Loss: 2.9433, 4.5954, 7.5387\n",
      "[1/50] Loss: 7.548\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 15 %\n",
      "Accuracy of the network on the 50000 train images fine: 3 %\n",
      "Average Accuracy of the network on the 50000 train images: 9 %\n",
      "Accuracy of the network on the 10000 test images coarse: 15 %\n",
      "Accuracy of the network on the 10000 test images fine: 3 %\n",
      "Average Accuracy of the network on the 10000 test images: 9 %\n",
      "tensor(0.6089)\n",
      "Epoch [2/50], Iter [20/0] Loss: 2.9482, 4.5892, 7.5374\n",
      "tensor(0.6110)\n",
      "Epoch [2/50], Iter [40/0] Loss: 2.9091, 4.5696, 7.4787\n",
      "tensor(0.6149)\n",
      "Epoch [2/50], Iter [60/0] Loss: 2.8701, 4.5826, 7.4527\n",
      "tensor(0.6098)\n",
      "Epoch [2/50], Iter [80/0] Loss: 2.9310, 4.5796, 7.5106\n",
      "tensor(0.6085)\n",
      "Epoch [2/50], Iter [100/0] Loss: 2.9453, 4.5782, 7.5235\n",
      "tensor(0.6130)\n",
      "Epoch [2/50], Iter [120/0] Loss: 2.8934, 4.5828, 7.4761\n",
      "tensor(0.6109)\n",
      "Epoch [2/50], Iter [140/0] Loss: 2.9151, 4.5771, 7.4922\n",
      "tensor(0.6125)\n",
      "Epoch [2/50], Iter [160/0] Loss: 2.9083, 4.5972, 7.5055\n",
      "tensor(0.6117)\n",
      "Epoch [2/50], Iter [180/0] Loss: 2.9001, 4.5690, 7.4692\n",
      "[2/50] Loss: 7.523\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 16 %\n",
      "Accuracy of the network on the 50000 train images fine: 4 %\n",
      "Average Accuracy of the network on the 50000 train images: 10 %\n",
      "Accuracy of the network on the 10000 test images coarse: 16 %\n",
      "Accuracy of the network on the 10000 test images fine: 4 %\n",
      "Average Accuracy of the network on the 10000 test images: 10 %\n",
      "tensor(0.6145)\n",
      "Epoch [3/50], Iter [20/0] Loss: 2.8716, 4.5769, 7.4485\n",
      "tensor(0.6114)\n",
      "Epoch [3/50], Iter [40/0] Loss: 2.9036, 4.5676, 7.4711\n",
      "tensor(0.6101)\n",
      "Epoch [3/50], Iter [60/0] Loss: 2.9207, 4.5697, 7.4904\n",
      "tensor(0.6103)\n",
      "Epoch [3/50], Iter [80/0] Loss: 2.9193, 4.5712, 7.4905\n",
      "tensor(0.6134)\n",
      "Epoch [3/50], Iter [100/0] Loss: 2.8838, 4.5750, 7.4588\n",
      "tensor(0.6110)\n",
      "Epoch [3/50], Iter [120/0] Loss: 2.9234, 4.5917, 7.5151\n",
      "tensor(0.6139)\n",
      "Epoch [3/50], Iter [140/0] Loss: 2.8778, 4.5750, 7.4528\n",
      "tensor(0.6119)\n",
      "Epoch [3/50], Iter [160/0] Loss: 2.9102, 4.5878, 7.4981\n",
      "tensor(0.6099)\n",
      "Epoch [3/50], Iter [180/0] Loss: 2.9365, 4.5910, 7.5275\n",
      "[3/50] Loss: 7.510\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 17 %\n",
      "Accuracy of the network on the 50000 train images fine: 5 %\n",
      "Average Accuracy of the network on the 50000 train images: 11 %\n",
      "Accuracy of the network on the 10000 test images coarse: 17 %\n",
      "Accuracy of the network on the 10000 test images fine: 5 %\n",
      "Average Accuracy of the network on the 10000 test images: 11 %\n",
      "tensor(0.6109)\n",
      "Epoch [4/50], Iter [20/0] Loss: 2.9225, 4.5881, 7.5106\n",
      "tensor(0.6071)\n",
      "Epoch [4/50], Iter [40/0] Loss: 2.9465, 4.5533, 7.4998\n",
      "tensor(0.6074)\n",
      "Epoch [4/50], Iter [60/0] Loss: 2.9309, 4.5349, 7.4657\n",
      "tensor(0.6098)\n",
      "Epoch [4/50], Iter [80/0] Loss: 2.9262, 4.5738, 7.5000\n",
      "tensor(0.6127)\n",
      "Epoch [4/50], Iter [100/0] Loss: 2.9019, 4.5917, 7.4936\n",
      "tensor(0.6112)\n",
      "Epoch [4/50], Iter [120/0] Loss: 2.9183, 4.5885, 7.5068\n",
      "tensor(0.6131)\n",
      "Epoch [4/50], Iter [140/0] Loss: 2.8873, 4.5754, 7.4627\n",
      "tensor(0.6145)\n",
      "Epoch [4/50], Iter [160/0] Loss: 2.8813, 4.5934, 7.4747\n",
      "tensor(0.6116)\n",
      "Epoch [4/50], Iter [180/0] Loss: 2.9128, 4.5862, 7.4990\n",
      "[4/50] Loss: 7.503\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 15 %\n",
      "Accuracy of the network on the 50000 train images fine: 4 %\n",
      "Average Accuracy of the network on the 50000 train images: 9 %\n",
      "Accuracy of the network on the 10000 test images coarse: 15 %\n",
      "Accuracy of the network on the 10000 test images fine: 4 %\n",
      "Average Accuracy of the network on the 10000 test images: 9 %\n",
      "tensor(0.6124)\n",
      "Epoch [5/50], Iter [20/0] Loss: 2.9000, 4.5814, 7.4814\n",
      "tensor(0.6109)\n",
      "Epoch [5/50], Iter [40/0] Loss: 2.9104, 4.5703, 7.4807\n",
      "tensor(0.6096)\n",
      "Epoch [5/50], Iter [60/0] Loss: 2.9309, 4.5758, 7.5067\n",
      "tensor(0.6124)\n",
      "Epoch [5/50], Iter [80/0] Loss: 2.8926, 4.5696, 7.4622\n",
      "tensor(0.6129)\n",
      "Epoch [5/50], Iter [100/0] Loss: 2.8873, 4.5714, 7.4587\n",
      "tensor(0.6106)\n",
      "Epoch [5/50], Iter [120/0] Loss: 2.9031, 4.5531, 7.4562\n",
      "tensor(0.6119)\n",
      "Epoch [5/50], Iter [140/0] Loss: 2.8956, 4.5650, 7.4606\n",
      "tensor(0.6118)\n",
      "Epoch [5/50], Iter [160/0] Loss: 2.9068, 4.5808, 7.4876\n",
      "tensor(0.6106)\n",
      "Epoch [5/50], Iter [180/0] Loss: 2.9079, 4.5604, 7.4683\n",
      "[5/50] Loss: 7.497\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 19 %\n",
      "Accuracy of the network on the 50000 train images fine: 5 %\n",
      "Average Accuracy of the network on the 50000 train images: 12 %\n",
      "Accuracy of the network on the 10000 test images coarse: 18 %\n",
      "Accuracy of the network on the 10000 test images fine: 5 %\n",
      "Average Accuracy of the network on the 10000 test images: 11 %\n",
      "tensor(0.6138)\n",
      "Epoch [6/50], Iter [20/0] Loss: 2.8868, 4.5872, 7.4740\n",
      "tensor(0.6127)\n",
      "Epoch [6/50], Iter [40/0] Loss: 2.9000, 4.5885, 7.4885\n",
      "tensor(0.6122)\n",
      "Epoch [6/50], Iter [60/0] Loss: 2.9004, 4.5795, 7.4798\n",
      "tensor(0.6110)\n",
      "Epoch [6/50], Iter [80/0] Loss: 2.9186, 4.5846, 7.5032\n",
      "tensor(0.6127)\n",
      "Epoch [6/50], Iter [100/0] Loss: 2.8815, 4.5592, 7.4407\n",
      "tensor(0.6113)\n",
      "Epoch [6/50], Iter [120/0] Loss: 2.9116, 4.5787, 7.4904\n",
      "tensor(0.6111)\n",
      "Epoch [6/50], Iter [140/0] Loss: 2.9054, 4.5654, 7.4708\n",
      "tensor(0.6107)\n",
      "Epoch [6/50], Iter [160/0] Loss: 2.9130, 4.5694, 7.4825\n",
      "tensor(0.6097)\n",
      "Epoch [6/50], Iter [180/0] Loss: 2.9338, 4.5820, 7.5158\n",
      "[6/50] Loss: 7.493\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 16 %\n",
      "Accuracy of the network on the 50000 train images fine: 5 %\n",
      "Average Accuracy of the network on the 50000 train images: 10 %\n",
      "Accuracy of the network on the 10000 test images coarse: 16 %\n",
      "Accuracy of the network on the 10000 test images fine: 5 %\n",
      "Average Accuracy of the network on the 10000 test images: 10 %\n",
      "tensor(0.6104)\n",
      "Epoch [7/50], Iter [20/0] Loss: 2.9086, 4.5571, 7.4657\n",
      "tensor(0.6101)\n",
      "Epoch [7/50], Iter [40/0] Loss: 2.9316, 4.5867, 7.5183\n",
      "tensor(0.6134)\n",
      "Epoch [7/50], Iter [60/0] Loss: 2.8776, 4.5652, 7.4428\n",
      "tensor(0.6104)\n",
      "Epoch [7/50], Iter [80/0] Loss: 2.9281, 4.5877, 7.5158\n",
      "tensor(0.6138)\n",
      "Epoch [7/50], Iter [100/0] Loss: 2.8709, 4.5636, 7.4344\n",
      "tensor(0.6096)\n",
      "Epoch [7/50], Iter [120/0] Loss: 2.9259, 4.5679, 7.4938\n",
      "tensor(0.6137)\n",
      "Epoch [7/50], Iter [140/0] Loss: 2.8701, 4.5591, 7.4292\n",
      "tensor(0.6119)\n",
      "Epoch [7/50], Iter [160/0] Loss: 2.8990, 4.5708, 7.4699\n",
      "tensor(0.6124)\n",
      "Epoch [7/50], Iter [180/0] Loss: 2.8974, 4.5773, 7.4747\n",
      "[7/50] Loss: 7.489\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 18 %\n",
      "Accuracy of the network on the 50000 train images fine: 5 %\n",
      "Average Accuracy of the network on the 50000 train images: 11 %\n",
      "Accuracy of the network on the 10000 test images coarse: 18 %\n",
      "Accuracy of the network on the 10000 test images fine: 5 %\n",
      "Average Accuracy of the network on the 10000 test images: 11 %\n",
      "tensor(0.6119)\n",
      "Epoch [8/50], Iter [20/0] Loss: 2.8981, 4.5684, 7.4665\n",
      "tensor(0.6135)\n",
      "Epoch [8/50], Iter [40/0] Loss: 2.8742, 4.5615, 7.4357\n",
      "tensor(0.6150)\n",
      "Epoch [8/50], Iter [60/0] Loss: 2.8608, 4.5697, 7.4305\n",
      "tensor(0.6107)\n",
      "Epoch [8/50], Iter [80/0] Loss: 2.9098, 4.5641, 7.4739\n",
      "tensor(0.6110)\n",
      "Epoch [8/50], Iter [100/0] Loss: 2.8940, 4.5448, 7.4388\n",
      "tensor(0.6103)\n",
      "Epoch [8/50], Iter [120/0] Loss: 2.9164, 4.5677, 7.4841\n",
      "tensor(0.6110)\n",
      "Epoch [8/50], Iter [140/0] Loss: 2.9032, 4.5592, 7.4624\n",
      "tensor(0.6120)\n",
      "Epoch [8/50], Iter [160/0] Loss: 2.8994, 4.5735, 7.4729\n",
      "tensor(0.6094)\n",
      "Epoch [8/50], Iter [180/0] Loss: 2.9233, 4.5615, 7.4848\n",
      "[8/50] Loss: 7.486\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 19 %\n",
      "Accuracy of the network on the 50000 train images fine: 5 %\n",
      "Average Accuracy of the network on the 50000 train images: 12 %\n",
      "Accuracy of the network on the 10000 test images coarse: 18 %\n",
      "Accuracy of the network on the 10000 test images fine: 5 %\n",
      "Average Accuracy of the network on the 10000 test images: 11 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6147)\n",
      "Epoch [9/50], Iter [20/0] Loss: 2.8565, 4.5569, 7.4134\n",
      "tensor(0.6145)\n",
      "Epoch [9/50], Iter [40/0] Loss: 2.8692, 4.5740, 7.4432\n",
      "tensor(0.6130)\n",
      "Epoch [9/50], Iter [60/0] Loss: 2.8831, 4.5663, 7.4495\n",
      "tensor(0.6145)\n",
      "Epoch [9/50], Iter [80/0] Loss: 2.8712, 4.5765, 7.4477\n",
      "tensor(0.6129)\n",
      "Epoch [9/50], Iter [100/0] Loss: 2.8922, 4.5789, 7.4711\n",
      "tensor(0.6115)\n",
      "Epoch [9/50], Iter [120/0] Loss: 2.9029, 4.5694, 7.4722\n",
      "tensor(0.6108)\n",
      "Epoch [9/50], Iter [140/0] Loss: 2.9210, 4.5836, 7.5047\n",
      "tensor(0.6103)\n",
      "Epoch [9/50], Iter [160/0] Loss: 2.8959, 4.5347, 7.4305\n",
      "tensor(0.6123)\n",
      "Epoch [9/50], Iter [180/0] Loss: 2.8903, 4.5640, 7.4543\n",
      "[9/50] Loss: 7.484\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 19 %\n",
      "Accuracy of the network on the 50000 train images fine: 5 %\n",
      "Average Accuracy of the network on the 50000 train images: 12 %\n",
      "Accuracy of the network on the 10000 test images coarse: 18 %\n",
      "Accuracy of the network on the 10000 test images fine: 5 %\n",
      "Average Accuracy of the network on the 10000 test images: 11 %\n",
      "tensor(0.6133)\n",
      "Epoch [10/50], Iter [20/0] Loss: 2.8885, 4.5809, 7.4694\n",
      "tensor(0.6126)\n",
      "Epoch [10/50], Iter [40/0] Loss: 2.8887, 4.5669, 7.4556\n",
      "tensor(0.6110)\n",
      "Epoch [10/50], Iter [60/0] Loss: 2.9002, 4.5562, 7.4565\n",
      "tensor(0.6112)\n",
      "Epoch [10/50], Iter [80/0] Loss: 2.9122, 4.5789, 7.4911\n",
      "tensor(0.6106)\n",
      "Epoch [10/50], Iter [100/0] Loss: 2.9189, 4.5770, 7.4959\n",
      "tensor(0.6102)\n",
      "Epoch [10/50], Iter [120/0] Loss: 2.8947, 4.5323, 7.4270\n",
      "tensor(0.6103)\n",
      "Epoch [10/50], Iter [140/0] Loss: 2.9102, 4.5574, 7.4676\n",
      "tensor(0.6110)\n",
      "Epoch [10/50], Iter [160/0] Loss: 2.9198, 4.5862, 7.5060\n",
      "tensor(0.6137)\n",
      "Epoch [10/50], Iter [180/0] Loss: 2.8679, 4.5559, 7.4239\n",
      "[10/50] Loss: 7.482\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 17 %\n",
      "Accuracy of the network on the 50000 train images fine: 5 %\n",
      "Average Accuracy of the network on the 50000 train images: 11 %\n",
      "Accuracy of the network on the 10000 test images coarse: 17 %\n",
      "Accuracy of the network on the 10000 test images fine: 4 %\n",
      "Average Accuracy of the network on the 10000 test images: 10 %\n",
      "tensor(0.6116)\n",
      "Epoch [11/50], Iter [20/0] Loss: 2.9046, 4.5737, 7.4782\n",
      "tensor(0.6116)\n",
      "Epoch [11/50], Iter [40/0] Loss: 2.9085, 4.5791, 7.4876\n",
      "tensor(0.6130)\n",
      "Epoch [11/50], Iter [60/0] Loss: 2.8806, 4.5628, 7.4435\n",
      "tensor(0.6116)\n",
      "Epoch [11/50], Iter [80/0] Loss: 2.8964, 4.5605, 7.4569\n",
      "tensor(0.6121)\n",
      "Epoch [11/50], Iter [100/0] Loss: 2.8925, 4.5638, 7.4563\n",
      "tensor(0.6124)\n",
      "Epoch [11/50], Iter [120/0] Loss: 2.8813, 4.5528, 7.4340\n",
      "tensor(0.6124)\n",
      "Epoch [11/50], Iter [140/0] Loss: 2.8981, 4.5793, 7.4774\n",
      "tensor(0.6151)\n",
      "Epoch [11/50], Iter [160/0] Loss: 2.8593, 4.5695, 7.4288\n",
      "tensor(0.6155)\n",
      "Epoch [11/50], Iter [180/0] Loss: 2.8568, 4.5738, 7.4307\n",
      "[11/50] Loss: 7.480\n",
      "50000\n",
      "Accuracy of the network on the 50000 train images coarse: 20 %\n",
      "Accuracy of the network on the 50000 train images fine: 6 %\n",
      "Average Accuracy of the network on the 50000 train images: 13 %\n",
      "Accuracy of the network on the 10000 test images coarse: 19 %\n",
      "Accuracy of the network on the 10000 test images fine: 6 %\n",
      "Average Accuracy of the network on the 10000 test images: 12 %\n",
      "tensor(0.6132)\n",
      "Epoch [12/50], Iter [20/0] Loss: 2.8857, 4.5756, 7.4613\n",
      "tensor(0.6125)\n",
      "Epoch [12/50], Iter [40/0] Loss: 2.8972, 4.5793, 7.4764\n",
      "tensor(0.6113)\n",
      "Epoch [12/50], Iter [60/0] Loss: 2.9010, 4.5628, 7.4639\n",
      "tensor(0.6145)\n",
      "Epoch [12/50], Iter [80/0] Loss: 2.8563, 4.5522, 7.4085\n",
      "tensor(0.6135)\n",
      "Epoch [12/50], Iter [100/0] Loss: 2.8767, 4.5661, 7.4429\n",
      "tensor(0.6149)\n",
      "Epoch [12/50], Iter [120/0] Loss: 2.8738, 4.5883, 7.4621\n",
      "tensor(0.6129)\n",
      "Epoch [12/50], Iter [140/0] Loss: 2.8849, 4.5684, 7.4533\n",
      "tensor(0.6134)\n",
      "Epoch [12/50], Iter [160/0] Loss: 2.8764, 4.5635, 7.4398\n",
      "tensor(0.6094)\n",
      "Epoch [12/50], Iter [180/0] Loss: 2.9115, 4.5424, 7.4538\n",
      "[12/50] Loss: 7.478\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# Loss and Optimizer\n",
    "\n",
    "#Can also try nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = Adam([i for i in net.parameters() if i.shape != torch.Size([100]) and i.shape != torch.Size([100, 200])], lr=learning_rate, weight_decay=0.03)\n",
    "optimizer2 = Adam([i for i in net.parameters() if i.shape != torch.Size([20]) and i.shape != torch.Size([20, 200])], lr=learning_rate, weight_decay=0.03)\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "trainc_acc = []\n",
    "valc_acc = []\n",
    "trainf_acc = []\n",
    "valf_acc = []\n",
    "\n",
    "loss_history = []\n",
    "lossc_history = []\n",
    "lossf_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labelc, labelf) in enumerate(train_loader):\n",
    "        net.train() # Change model to 'train' mode.\n",
    "    #     for i in range(cnn_training_data_X.shape[0]):\n",
    "        images = Variable(images, requires_grad=True) #unsqueeze used to make a 4d tensor because \n",
    "    #     print images.shape\n",
    "        labelc = Variable(labelc, requires_grad=False)\n",
    "        labelf = Variable(labelf, volatile=True)\n",
    "        #labels = [labelc, labelf]\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        net.zero_grad()\n",
    "        #outputs = net(images)\n",
    "        \n",
    "        \n",
    "        outc, outf = net(images)\n",
    "        lossc = criterion(outc, labelc)\n",
    "        lossf = criterion(outf, labelf)\n",
    "        loss = lossc + lossf\n",
    "        \n",
    "        alpha_ = lossf/(lossc+lossf)\n",
    "        \n",
    "        #loss = criterion(outputs, labelc)\n",
    "        #loss.backward()\n",
    "        \n",
    "        loss_history.append(loss.data)\n",
    "        lossc_history.append(lossc.data)\n",
    "        lossf_history.append(lossf.data)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer1.step(alpha=alpha_.data)\n",
    "        optimizer2.step(alpha=(1-alpha_.data))\n",
    "        \n",
    "        #for f in net.parameters():\n",
    "            #if f.shape != torch.Size([100]) and f.shape != torch.Size([100, 200]):\n",
    "            #f.data.sub_(f.grad.data * learning_rate)\n",
    "        if (i+1) % 20 == 0:\n",
    "            print(alpha_.data)\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f, %.4f, %.4f' \n",
    "                   %(epoch+1, epochs, i+1, len(X_train.shape)//batch_size, lossc.data, lossf.data,loss.data))\n",
    "    print('[%d/%d] Loss: %.3f' % (epoch+1, epochs, np.mean(loss_history)))\n",
    "    \n",
    "    \n",
    "    correctc = 0\n",
    "    correctf = 0\n",
    "    total = 0\n",
    "    net.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            images, labelc, labelf = data\n",
    "            outputc, outputf = net(images)\n",
    "            _, predictedc = torch.max(outputc.data, 1)\n",
    "            _, predictedf = torch.max(outputf.data, 1)\n",
    "            total += labelc.size(0)\n",
    "            correctc += (predictedc == labelc).sum().item()\n",
    "            correctf += (predictedf == labelf).sum().item()\n",
    "    print(total)\n",
    "    trainc_acc_val = (100 * correctc / total)\n",
    "    trainf_acc_val = (100 * correctf / total)\n",
    "    train_acc_val = (trainc_acc_val + trainf_acc_val)/2.0\n",
    "    trainc_acc.append(trainc_acc_val)\n",
    "    trainf_acc.append(trainf_acc_val)\n",
    "    train_acc.append(train_acc_val)\n",
    "    print('Accuracy of the network on the 50000 train images coarse: %d %%' % (trainc_acc_val))\n",
    "    print('Accuracy of the network on the 50000 train images fine: %d %%' % (trainf_acc_val))\n",
    "    print('Average Accuracy of the network on the 50000 train images: %d %%' % (train_acc_val))\n",
    "          \n",
    "    correctc = 0\n",
    "    correctf = 0\n",
    "    total = 0\n",
    "    net.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labelc, labelf = data\n",
    "            outputc, outputf = net(images)\n",
    "            _, predictedc = torch.max(outputc.data, 1)\n",
    "            _, predictedf = torch.max(outputf.data, 1)\n",
    "            total += labelc.size(0)\n",
    "            correctc += (predictedc == labelc).sum().item()\n",
    "            correctf += (predictedf == labelf).sum().item()\n",
    "\n",
    "    valc_acc_val = (100 * correctc / total)\n",
    "    valf_acc_val = (100 * correctf / total)\n",
    "    val_acc_val = (valc_acc_val + valf_acc_val)/2.0\n",
    "    valc_acc.append(valc_acc_val)\n",
    "    valf_acc.append(valf_acc_val)\n",
    "    val_acc.append(val_acc_val)\n",
    "    print('Accuracy of the network on the 10000 test images coarse: %d %%' % (valc_acc_val))\n",
    "    print('Accuracy of the network on the 10000 test images fine: %d %%' % (valf_acc_val))\n",
    "    print('Average Accuracy of the network on the 10000 test images: %d %%' % (val_acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot train/val accuracies\n",
    "print(train_acc)\n",
    "plt.title(\"Train/Test Acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel('acc')\n",
    "plt.plot(train_acc, color='red')\n",
    "plt.plot(val_acc, color='blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
